{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Add,\n",
    "    ZeroPadding2D,\n",
    "    UpSampling2D,\n",
    "    Concatenate,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from time import time\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError(\"Composition of empty sequence not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wraps(Conv2D)\n",
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {\"kernel_regularizer\": l2(5e-4)}\n",
    "    darknet_conv_kwargs[\"padding\"] = (\n",
    "        \"valid\" if kwargs.get(\"strides\") == (2, 2) else \"same\"\n",
    "    )\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {\"use_bias\": False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "    )\n",
    "\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    \"\"\"A series of resblocks starting with a downsampling Convolution2D\"\"\"\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = DarknetConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters // 2, (1, 1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (3, 3)),\n",
    "        )(x)\n",
    "        x = Add()([x, y])\n",
    "    return x\n",
    "\n",
    "\n",
    "def darknet_body(x):\n",
    "    \"\"\"Darknent body having 52 Convolution2D layers\"\"\"\n",
    "    x = DarknetConv2D_BN_Leaky(32, (3, 3))(x)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    \"\"\"6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer\"\"\"\n",
    "    x = compose(\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
    "    )(x)\n",
    "    y = compose(\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D(out_filters, (1, 1)),\n",
    "    )(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V3 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors * (num_classes + 5))\n",
    "\n",
    "    x = compose(DarknetConv2D_BN_Leaky(256, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors * (num_classes + 5))\n",
    "\n",
    "    x = compose(DarknetConv2D_BN_Leaky(128, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors * (num_classes + 5))\n",
    "\n",
    "    return Model(inputs, [y1, y2, y3])\n",
    "\n",
    "\n",
    "def tiny_yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create Tiny YOLO_v3 model CNN body in keras.\"\"\"\n",
    "    x1 = compose(\n",
    "        DarknetConv2D_BN_Leaky(16, (3, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(32, (3, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(64, (3, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(128, (3, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(256, (3, 3)),\n",
    "    )(inputs)\n",
    "    x2 = compose(\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(512, (3, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(256, (1, 1)),\n",
    "    )(x1)\n",
    "    y1 = compose(\n",
    "        DarknetConv2D_BN_Leaky(512, (3, 3)),\n",
    "        DarknetConv2D(num_anchors * (num_classes + 5), (1, 1)),\n",
    "    )(x2)\n",
    "\n",
    "    x2 = compose(DarknetConv2D_BN_Leaky(128, (1, 1)), UpSampling2D(2))(x2)\n",
    "    y2 = compose(\n",
    "        Concatenate(),\n",
    "        DarknetConv2D_BN_Leaky(256, (3, 3)),\n",
    "        DarknetConv2D(num_anchors * (num_classes + 5), (1, 1)),\n",
    "    )([x2, x1])\n",
    "\n",
    "    return Model(inputs, [y1, y2])\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3]  # height, width\n",
    "    grid_y = K.tile(\n",
    "        K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1],\n",
    "    )\n",
    "    grid_x = K.tile(\n",
    "        K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1],\n",
    "    )\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5]\n",
    "    )\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(\n",
    "        grid_shape[::-1], K.dtype(feats)\n",
    "    )\n",
    "    box_wh = (\n",
    "        K.exp(feats[..., 2:4])\n",
    "        * anchors_tensor\n",
    "        / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    )\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    \"\"\"Get corrected boxes\"\"\"\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2.0 / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.0)\n",
    "    box_maxes = box_yx + (box_hw / 2.0)\n",
    "    boxes = K.concatenate(\n",
    "        [\n",
    "            box_mins[..., 0:1],  # y_min\n",
    "            box_mins[..., 1:2],  # x_min\n",
    "            box_maxes[..., 0:1],  # y_max\n",
    "            box_maxes[..., 1:2],  # x_max\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
    "    \"\"\"Process Conv layer output\"\"\"\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(\n",
    "        feats, anchors, num_classes, input_shape\n",
    "    )\n",
    "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = K.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
    "    return boxes, box_scores\n",
    "\n",
    "\n",
    "def yolo_eval(\n",
    "    yolo_outputs,\n",
    "    anchors,\n",
    "    num_classes,\n",
    "    image_shape,\n",
    "    max_boxes=20,\n",
    "    score_threshold=0.6,\n",
    "    iou_threshold=0.5,\n",
    "):\n",
    "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
    "    num_layers = len(yolo_outputs)\n",
    "    anchor_mask = (\n",
    "        [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "    )  # default setting\n",
    "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    for l in range(num_layers):\n",
    "        _boxes, _box_scores = yolo_boxes_and_scores(\n",
    "            yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]],\n",
    "            num_classes,\n",
    "            input_shape,\n",
    "            image_shape,\n",
    "        )\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = K.concatenate(boxes, axis=0)\n",
    "    box_scores = K.concatenate(box_scores, axis=0)\n",
    "\n",
    "    mask = box_scores >= score_threshold\n",
    "    max_boxes_tensor = K.constant(max_boxes, dtype=\"int32\")\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(num_classes):\n",
    "        # TODO: use keras backend instead of tf.\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold\n",
    "        )\n",
    "        class_boxes = K.gather(class_boxes, nms_index)\n",
    "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "        classes = K.ones_like(class_box_scores, \"int32\") * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = K.concatenate(boxes_, axis=0)\n",
    "    scores_ = K.concatenate(scores_, axis=0)\n",
    "    classes_ = K.concatenate(classes_, axis=0)\n",
    "\n",
    "    return boxes_, scores_, classes_\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    \"\"\"Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        true_boxes[..., 4] < num_classes\n",
    "    ).all(), \"class id must be less than num_classes\"\n",
    "    num_layers = len(anchors) // 3  # default setting\n",
    "    anchor_mask = (\n",
    "        [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "    )\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype=\"float32\")\n",
    "    input_shape = np.array(input_shape, dtype=\"int32\")\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape // {0: 32, 1: 16, 2: 8}[l] for l in range(num_layers)]\n",
    "    y_true = [\n",
    "        np.zeros(\n",
    "            (\n",
    "                m,\n",
    "                grid_shapes[l][0],\n",
    "                grid_shapes[l][1],\n",
    "                len(anchor_mask[l]),\n",
    "                5 + num_classes,\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "        )\n",
    "        for l in range(num_layers)\n",
    "    ]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.0\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0] > 0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh) == 0:\n",
    "            continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.0\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.0)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b, t, 0] * grid_shapes[l][1]).astype(\n",
    "                        \"int32\"\n",
    "                    )\n",
    "                    j = np.floor(true_boxes[b, t, 1] * grid_shapes[l][0]).astype(\n",
    "                        \"int32\"\n",
    "                    )\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b, t, 4].astype(\"int32\")\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5 + c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    \"\"\"Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh / 2.0\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh / 2.0\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.0)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=0.5, print_loss=False):\n",
    "    \"\"\"Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    \"\"\"\n",
    "    num_layers = len(anchors) // 3  # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = (\n",
    "        [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "    )\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [\n",
    "        K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0]))\n",
    "        for l in range(num_layers)\n",
    "    ]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(\n",
    "            yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]],\n",
    "            num_classes,\n",
    "            input_shape,\n",
    "            calc_loss=True,\n",
    "        )\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(\n",
    "            y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1]\n",
    "        )\n",
    "        raw_true_wh = K.switch(\n",
    "            object_mask, raw_true_wh, K.zeros_like(raw_true_wh)\n",
    "        )  # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, \"bool\")\n",
    "\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(\n",
    "                y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0]\n",
    "            )\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(\n",
    "                b, K.cast(best_iou < ignore_thresh, K.dtype(true_box))\n",
    "            )\n",
    "            return b + 1, ignore_mask\n",
    "\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(\n",
    "            lambda b, *args: b < m, loop_body, [0, ignore_mask]\n",
    "        )\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = (\n",
    "            object_mask\n",
    "            * box_loss_scale\n",
    "            * K.binary_crossentropy(raw_true_xy, raw_pred[..., 0:2], from_logits=True)\n",
    "        )\n",
    "        wh_loss = (\n",
    "            object_mask\n",
    "            * box_loss_scale\n",
    "            * 0.5\n",
    "            * K.square(raw_true_wh - raw_pred[..., 2:4])\n",
    "        )\n",
    "        confidence_loss = (\n",
    "            object_mask\n",
    "            * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True)\n",
    "            + (1 - object_mask)\n",
    "            * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True)\n",
    "            * ignore_mask\n",
    "        )\n",
    "        class_loss = object_mask * K.binary_crossentropy(\n",
    "            true_class_probs, raw_pred[..., 5:], from_logits=True\n",
    "        )\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.Print(\n",
    "                loss,\n",
    "                [\n",
    "                    loss,\n",
    "                    xy_loss,\n",
    "                    wh_loss,\n",
    "                    confidence_loss,\n",
    "                    class_loss,\n",
    "                    K.sum(ignore_mask),\n",
    "                ],\n",
    "                message=\"loss: \",\n",
    "            )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_wrapper(\n",
    "    annotation_lines, batch_size, input_shape, anchors, num_classes\n",
    "):\n",
    "    n = len(annotation_lines)\n",
    "    if n == 0 or batch_size <= 0:\n",
    "        return None\n",
    "    return data_generator(\n",
    "        annotation_lines, batch_size, input_shape, anchors, num_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    \"\"\"data generator for fit_generator\"\"\"\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i == 0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(\n",
    "    annotation_line,\n",
    "    input_shape,\n",
    "    random=True,\n",
    "    max_boxes=20,\n",
    "    jitter=0.3,\n",
    "    hue=0.1,\n",
    "    sat=1.5,\n",
    "    val=1.5,\n",
    "    proc_img=True,\n",
    "):\n",
    "    \"\"\"random preprocessing for real-time data augmentation\"\"\"\n",
    "\n",
    "    # This type of splitting makes sure that it is compatible with spaces in folder names\n",
    "    # We split at the first space that is followed by a number\n",
    "    tmp_split = re.split(\"( \\d)\", annotation_line, maxsplit=1)\n",
    "    if len(tmp_split) > 2:\n",
    "        line = tmp_split[0], tmp_split[1] + tmp_split[2]\n",
    "        print(tmp_split[0])\n",
    "        print(tmp_split[1])\n",
    "        print(tmp_split[2])\n",
    "        print(line)\n",
    "    else:\n",
    "        line = tmp_split\n",
    "        print(line)\n",
    "    # line[0] contains the filename\n",
    "\n",
    "    image = Image.open(line[0])\n",
    "    # The rest of the line includes bounding boxes\n",
    "    line = line[1].split(\" \")\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int, box.split(\",\")))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w / iw, h / ih)\n",
    "        nw = int(iw * scale)\n",
    "        nh = int(ih * scale)\n",
    "        dx = (w - nw) // 2\n",
    "        dy = (h - nh) // 2\n",
    "        image_data = 0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw, nh), Image.BICUBIC)\n",
    "            new_image = Image.new(\"RGB\", (w, h), (128, 128, 128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image) / 255.0\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes, 5))\n",
    "        if len(box) > 0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box) > max_boxes:\n",
    "                box = box[:max_boxes]\n",
    "            box[:, [0, 2]] = box[:, [0, 2]] * scale + dx\n",
    "            box[:, [1, 3]] = box[:, [1, 3]] * scale + dy\n",
    "            box_data[: len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w / h * rand(1 - jitter, 1 + jitter) / rand(1 - jitter, 1 + jitter)\n",
    "    scale = rand(0.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale * h)\n",
    "        nw = int(nh * new_ar)\n",
    "    else:\n",
    "        nw = int(scale * w)\n",
    "        nh = int(nw / new_ar)\n",
    "    image = image.resize((nw, nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w - nw))\n",
    "    dy = int(rand(0, h - nh))\n",
    "    new_image = Image.new(\"RGB\", (w, h), (128, 128, 128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand() < 0.5\n",
    "    if flip:\n",
    "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand() < 0.5 else 1 / rand(1, sat)\n",
    "    val = rand(1, val) if rand() < 0.5 else 1 / rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image) / 255.0)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0] > 1] -= 1\n",
    "    x[..., 0][x[..., 0] < 0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x > 1] = 1\n",
    "    x[x < 0] = 0\n",
    "    image_data = hsv_to_rgb(x)  # numpy array, 0 to 1\n",
    "\n",
    "    # make gray\n",
    "    gray = rand() < 0.2\n",
    "    if gray:\n",
    "        image_gray = np.dot(image_data, [0.299, 0.587, 0.114])\n",
    "        # a gray RGB image is GGG\n",
    "        image_data = np.moveaxis(np.stack([image_gray, image_gray, image_gray]), 0, -1)\n",
    "\n",
    "    # invert colors\n",
    "    invert = rand() < 0.1\n",
    "    if invert:\n",
    "        image_data = 1.0 - image_data\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes, 5))\n",
    "    if len(box) > 0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0, 2]] = box[:, [0, 2]] * nw / iw + dx\n",
    "        box[:, [1, 3]] = box[:, [1, 3]] * nh / ih + dy\n",
    "        if flip:\n",
    "            box[:, [0, 2]] = w - box[:, [2, 0]]\n",
    "        box[:, 0:2][box[:, 0:2] < 0] = 0\n",
    "        box[:, 2][box[:, 2] > w] = w\n",
    "        box[:, 3][box[:, 3] > h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w > 1, box_h > 1)]  # discard invalid box\n",
    "        if len(box) > max_boxes:\n",
    "            box = box[:max_boxes]\n",
    "        box_data[: len(box)] = box\n",
    "\n",
    "    return image_data, box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand(a=0, b=1):\n",
    "    return np.random.rand() * (b - a) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    \"\"\"loads the classes\"\"\"\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    \"\"\"loads the anchors from a file\"\"\"\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(\",\")]\n",
    "    return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    input_shape,\n",
    "    anchors,\n",
    "    num_classes,\n",
    "    load_pretrained=True,\n",
    "    freeze_body=2,\n",
    "    weights_path=\"keras_yolo3/model_data/yolo_weights.h5\",\n",
    "):\n",
    "    \"\"\"create the training model\"\"\"\n",
    "    K.clear_session()  # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [\n",
    "        Input(\n",
    "            shape=(\n",
    "                h // {0: 32, 1: 16, 2: 8}[l],\n",
    "                w // {0: 32, 1: 16, 2: 8}[l],\n",
    "                num_anchors // 3,\n",
    "                num_classes + 5,\n",
    "            )\n",
    "        )\n",
    "        for l in range(3)\n",
    "    ]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors // 3, num_classes)\n",
    "    print(\n",
    "        \"Create YOLOv3 model with {} anchors and {} classes.\".format(\n",
    "            num_anchors, num_classes\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print(\"Load weights {}.\".format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers) - 3)[freeze_body - 1]\n",
    "            for i in range(num):\n",
    "                model_body.layers[i].trainable = False\n",
    "            print(\n",
    "                \"Freeze the first {} layers of total {} layers.\".format(\n",
    "                    num, len(model_body.layers)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    model_loss = Lambda(\n",
    "        yolo_loss,\n",
    "        output_shape=(1,),\n",
    "        name=\"yolo_loss\",\n",
    "        arguments={\n",
    "            \"anchors\": anchors,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"ignore_thresh\": 0.5,\n",
    "        },\n",
    "    )([*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiny_model(\n",
    "    input_shape,\n",
    "    anchors,\n",
    "    num_classes,\n",
    "    load_pretrained=True,\n",
    "    freeze_body=2,\n",
    "    weights_path=\"keras_yolo3/model_data/tiny_yolo_weights.h5\",\n",
    "):\n",
    "    \"\"\"create the training model, for Tiny YOLOv3\"\"\"\n",
    "    K.clear_session()  # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [\n",
    "        Input(\n",
    "            shape=(\n",
    "                h // {0: 32, 1: 16}[l],\n",
    "                w // {0: 32, 1: 16}[l],\n",
    "                num_anchors // 2,\n",
    "                num_classes + 5,\n",
    "            )\n",
    "        )\n",
    "        for l in range(2)\n",
    "    ]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors // 2, num_classes)\n",
    "    print(\n",
    "        \"Create Tiny YOLOv3 model with {} anchors and {} classes.\".format(\n",
    "            num_anchors, num_classes\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print(\"Load weights {}.\".format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers) - 2)[freeze_body - 1]\n",
    "            for i in range(num):\n",
    "                model_body.layers[i].trainable = False\n",
    "            print(\n",
    "                \"Freeze the first {} layers of total {} layers.\".format(\n",
    "                    num, len(model_body.layers)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    model_loss = Lambda(\n",
    "        yolo_loss,\n",
    "        output_shape=(1,),\n",
    "        name=\"yolo_loss\",\n",
    "        arguments={\n",
    "            \"anchors\": anchors,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"ignore_thresh\": 0.7,\n",
    "        },\n",
    "    )([*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangeToOtherMachine(filelist, repo=\"TrainYourOwnYOLO-master\\TrainYourOwnYOLO-master\", remote_machine=\"\"):\n",
    "    \"\"\"\n",
    "    Takes a list of file_names located in a repo and changes it to the local machines file names. File must be executed from withing the repository\n",
    "\n",
    "    Example:\n",
    "\n",
    "    '/home/ubuntu/TrainYourOwnYOLO/Data/Street_View_Images/vulnerable/test.jpg'\n",
    "\n",
    "    Get's converted to\n",
    "    \n",
    "    'C:/Users/Anton/TrainYourOwnYOLO/Data/Street_View_Images/vulnerable/test.jpg'\n",
    "\n",
    "    \"\"\"\n",
    "    filelist = [x.replace(\"\\\\\", \"/\") for x in filelist]\n",
    "    if repo[-1] == \"/\":\n",
    "        repo = repo[:-1]\n",
    "    if remote_machine:\n",
    "        prefix = remote_machine.replace(\"\\\\\", \"/\")\n",
    "    else:\n",
    "        prefix = ((os.getcwd().split(repo))[0]).replace(\"\\\\\", \"/\")\n",
    "    print(os.getcwd())\n",
    "    print(prefix)\n",
    "    new_list = []\n",
    "\n",
    "    for file in filelist:\n",
    "        print(file)\n",
    "        repo=\"TrainYourOwnYOLO-master/TrainYourOwnYOLO-master\"\n",
    "        suffix = (file.split(repo))[1]\n",
    "        if suffix[0] == \"/\":\n",
    "            suffix = suffix[1:]\n",
    "        print(suffix)\n",
    "        new_list.append(os.path.join(prefix, repo + \"/\", suffix).replace(\"\\\\\", \"/\"))\n",
    "    print(\n",
    "        \"8888888888888888888*********************************98888888888888888888888888888888888\"\n",
    "    )\n",
    "    #print(new_list)\n",
    "    return new_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
